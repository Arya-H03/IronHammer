
Data Locality and CPU Caching:

Modern CPUs heavily rely on multi level cache hierarchies to bridge the performance gap between 
the processor core's execution units and the slower main memory. 

CPU -> Divided into multiple sets -> Each set has a fixed number of cache lines (64 bytes)

CPUs implement prefetchers which predict future memory access and try to load cache lines ahead of time. With this 
in mind it will benefit the prefetcher if data is stored contiguously and therefore more predictable.

SOA vs AOS:

- SOA is generally better due to contigious storage of similar data. Moreover, iterating over SOA tends to be more predictable and cache coherent.
- Although branching behavior via flags can make AOS a better choice in smaller component counts.
- Generally for the ECS design pattern, SOA is a better choice
- Try to have SOA arrays be aligned with SIMD loads.

Zero Cost Abstractions:

Curiously Recurring Template Pattern (CRTP) uses static polymorphism by having a base class template accept a derived class as a parameter.

templaye<typename Derived>
class SystemBase
{
public:

	void Update(float dt)
	{
		static_cast<Derived*>(this)->Update_Impl(dt);
	}
}

class VelocitySystem : SystemBase<VelocitySystem>
{
public:
	
	void Update_Impl(float dt)
	{
		//Logic
	}
}

class Engine
{
	VelocitySystem velocitySystem;
	velocitySystem.Update(); //Allows polymorphism without the overhead 
}


Component Storage Strategies

1. Dense-Sparse Mapping

The key idea is to use a sparse and dense array to map indicies in the sparse array to the component in dense array.

void Insert(int id, Component data)
{
	dense[size] = data; 
	denseIDs[size] = id;
	sparse[id] = size;
	size++;
}

void Remove(int id)
{
	int index = sparse[id];
	int last = size - 1;

	if(index != last)
	{
		dense[index] = dense[last];
		denseIDs[index] = denseIDs[last];
		sparse[denseIDs[last]] = index;
	}

	size--;
}

2.	Pages Vectors

Breaks down ID space into multiple pages. 

void Insert(int id, Component data)
{
	int pageIndex = id / pageCapacity;
	int offset = id % pageCapacity;

	if(!pages[pageIndex]) // Allocate new page
	Page &page = *pages[pageIndex];
	page.dense[page.size] = data;
	page.denseIDs[page.size] = id;
	page.sparse[id] = page.size;
	page.size ++;
}

3. Efficient Query Filtering

We we aim for a query pipeline with 3 seperate filter that get progressively more expensive. A Bitset, a bloom filter and a hashed archetype signature. 